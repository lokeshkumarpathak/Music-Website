<!DOCTYPE html>
<html>
<head>
  <title>Emotion Detection</title>
  <script src="face-api.js"></script>
</head>
<body>
  <video id="video" width="640" height="480" autoplay></video>
  <canvas id="canvas" width="640" height="480"></canvas>
  <p id="output"></p>

  <!-- Your modal HTML -->
  <div class="modal fade" id="exampleModal" tabindex="-1" aria-labelledby="exampleModalLabel" aria-hidden="true">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <h5 class="modal-title" id="exampleModalLabel"></h5>
          <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
        </div>
        <div class="modal-body" id="modalContent">
          <!-- Content loaded dynamically will appear here -->
        </div>
      </div>
    </div>
  </div>

  <script>
    let pageOpened = false;

    async function setupCamera() {
      const video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
      video.srcObject = stream;
      await video.play();
    }

    async function detectEmotion() {
      const video = document.getElementById('video');
      const canvas = document.getElementById('canvas');
      const context = canvas.getContext('2d');

      const faceDetectionOptions = new faceapi.TinyFaceDetectorOptions({ inputSize: 512 });
      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
      await faceapi.nets.faceExpressionNet.loadFromUri('/models');

      setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video, faceDetectionOptions)
                                         .withFaceLandmarks()
                                         .withFaceExpressions();

        context.clearRect(0, 0, canvas.width, canvas.height);
        context.drawImage(video, 0, 0, canvas.width, canvas.height);

        detections.forEach(detection => {
          const { expressions } = detection;
          let emotionLabel = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);
          document.getElementById('output').innerText = `Detected emotion: ${emotionLabel}`;

          // Open URL based on emotion if a page has not been opened yet
          if (!pageOpened) {
            switch (emotionLabel) {
              case 'neutral':
                loadContent('neutral.html');
                pageOpened = true;
                break;
              case 'happy':
                loadContent('happy2.html');
                pageOpened = true;
                break;
              case 'sad':
                loadContent('sad.html');
                pageOpened = true;
                break;
              case 'angry':
                loadContent('angry.html');
                pageOpened = true;
                break;
              default:
                break;
            }
          }
        });
      }, 100);
    }

    window.addEventListener('beforeunload', function() {
      // Reset pageOpened flag when navigating away from the page
      pageOpened = false;
    });

    // Function to load content using AJAX
    function loadContent(pageUrl) {
        $.get(pageUrl, function(data) {
            // Display fetched content in a modal
            $('#modalContent').html(data);
            $('#exampleModal').modal('show');
        }).fail(function() {
            console.log('Error loading page.');
        });
    }

    setupCamera().then(detectEmotion);
  </script>
</body>
</html>